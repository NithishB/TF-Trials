{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Cell():\n",
    "  \n",
    "  def __init__(self, units, inputs):\n",
    "    \"\"\"\n",
    "    Create a simple LSTM cell with specified number of units\n",
    "    Arguments:\n",
    "    units - number of hidden layer dimensions\n",
    "    \"\"\"\n",
    "    self.units = units\n",
    "    self.inputs = inputs\n",
    "    \n",
    "  def _wt_bias_init_(self):\n",
    "    \n",
    "    with tf.variable_scope(\"weights\", reuse=tf.AUTO_REUSE):\n",
    "      self.ig_input_wt = tf.get_variable(name=\"ig_input_weight\", shape=(tf.shape(inputs)[2],self.units), dtype=tf.float32)\n",
    "      self.ig_hidden_wt = tf.get_variable(name=\"ig_hidden_weight\", shape=(self.units,self.units), dtype=tf.float32)\n",
    "      self.ig_bias = tf.get_variable(name=\"ig_bias\", shape=(self.units), dtype=tf.float32)\n",
    "      \n",
    "      self.fg_input_wt = tf.get_variable(name=\"fg_input_weight\", shape=(tf.shape(inputs)[2],self.units), dtype=tf.float32)\n",
    "      self.fg_hidden_wt = tf.get_variable(name=\"fg_hidden_weight\", shape=(self.units,self.units), dtype=tf.float32)\n",
    "      self.fg_bias = tf.get_variable(name=\"fg_bias\", shape=(self.units), dtype=tf.float32)\n",
    "      \n",
    "      self.og_input_wt = tf.get_variable(name=\"og_input_weight\", shape=(tf.shape(inputs)[2],self.units), dtype=tf.float32)\n",
    "      self.og_hidden_wt = tf.get_variable(name=\"og_hidden_weight\", shape=(self.units,self.units), dtype=tf.float32)\n",
    "      self.og_bias = tf.get_variable(name=\"og_bias\", shape=(self.units), dtype=tf.float32)\n",
    "      \n",
    "      self.cs_input_wt = tf.get_variable(name=\"cs_input_weight\", shape=(tf.shape(inputs)[2],self.units), dtype=tf.float32)\n",
    "      self.cs_hidden_wt = tf.get_variable(name=\"cs_hidden_weight\", shape=(self.units,self.units), dtype=tf.float32)\n",
    "      self.cs_bias = tf.get_variable(name=\"cs_bias\", shape=(self.units), dtype=tf.float32)\n",
    "      \n",
    "      self.output_wt = tf.get_variable(name=\"output_wt\", shape=(self.units, 1), dtype=tf.float32)\n",
    "      self.output_bias = tf.get_variable(name=\"output_bias\", shape=(1), dtype=tf.float32)\n",
    "    \n",
    "  def _loop_calc_(self):\n",
    "    \n",
    "    self._wt_bias_init_()\n",
    "\n",
    "    with tf.variable_scope(\"loop\", reuse=tf.AUTO_REUSE):\n",
    "      outputs, states = [], []\n",
    "        \n",
    "      for i in range(tf.shape(self.inputs)[0]):\n",
    "        batch_state = tf.zeros(shape=(1,self.units), dtype=tf.float32)\n",
    "        batch_output = tf.zeros(shape=(1,self.units), dtype=tf.float32)\n",
    "            \n",
    "        for j in range(tf.shape(self.inputs)[1]):\n",
    "          ig = tf.sigmoid(tf.add(tf.matmul(self.inputs[i][j],self.ig_input_wt),tf.matmul(batch_output,self.ig_hidden_wt),tf.ig_bias))\n",
    "          fg = tf.sigmoid(tf.add(tf.matmul(self.inputs[i][j],self.fg_input_wt),tf.matmul(batch_output,self.fg_hidden_wt),tf.fg_bias))\n",
    "          og = tf.sigmoid(tf.add(tf.matmul(self.inputs[i][j],self.og_input_wt),tf.matmul(batch_output,self.og_hidden_wt),tf.og_bias))\n",
    "          cs_in = tf.tanh(tf.add(tf.matmul(self.inputs[i][j],self.cs_input_wt),tf.matmul(batch_output,self.cs_hidden_wt),tf.cs_bias))\n",
    "\n",
    "          batch_state = state*fg + ig*cs_in\n",
    "          batch_output = og*tf.tanh(batch_state)\n",
    "          \n",
    "        outputs.append(tf.add(tf.matmul(batch_output,self.output_wt), self.output_bias))\n",
    "        states.append(batch_state)\n",
    "        \n",
    "      return outputs, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "units = 256\n",
    "time_Steps = 10\n",
    "features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(dtype=tf.float32, shape=(batch_size, time_steps, features))\n",
    "targets = tf.placeholder(dtype=tf.float32, shape=(batch_size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM_Cell(units=units, inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  writer = tf.summary.FileWriter(\".\", graph=sess.graph)\n",
    "  lstm._loop_calc_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
